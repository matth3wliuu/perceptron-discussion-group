{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math \n",
    "from functools import lru_cache\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV , KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    '''\n",
    "    - This class is used to load data from the various .csv files and convert them to pd.DataFrame. \n",
    "    - Please feel free to load more .csv files here if you wish to use them. \n",
    "    - This class stores three data sets\n",
    "        - training set: used to train the models (determine paramters)\n",
    "        - dev set: used for cross validation (determine best hyper parameters)\n",
    "        - test set: used to test the final model (determine performance)\n",
    "        - ! PLEASE DO NOT USE THE TEST SET FOR ANYTHING OTHER THAN TESTING THE FINAL MODEL !\n",
    "    - The init function currently:\n",
    "        - loads training_files/trades.csv, training_files/stock_list.csv, training_files/stock_prices.csv and supplemental_files/stock_prices.csv\n",
    "        - Takes the most recently 6 months of data from supplemental_files/stock_prices.csv as a validation set and the rest is addded to training/stock_prices.csv\n",
    "        - splits the modified training_file/stock_prices.csv into a training set and a test set (defaults to 70% training, 30% test with seed = 42)\n",
    "    - Any methods that returns data will return a pd.DataFrame.\n",
    "    '''\n",
    "\n",
    "    TRAINING_DIRECTORY = \"train_files/\"\n",
    "    TEST_DIRECTORY = \"example_test_files/\"\n",
    "    SUPPLEMENTAL_DIRECTORY = \"supplemental_files/\"\n",
    "    \n",
    "    # * If dir is not None, it will load the data from the given directory. Otherwise, it will load the default data from the competition.\n",
    "    def __init__(self, seed = 42, train_size = 0.70, dir = None):\n",
    "        if dir is not None:\n",
    "            training_data = pd.read_csv(dir + \"train\")\n",
    "            dev_data = pd.read_csv(dir + \"dev\")\n",
    "            test_data = pd.read_csv(dir + \"test\")\n",
    "            \n",
    "            self.X_train = training_data.drop([\"Target\", \"RowId\"], axis = 1)\n",
    "            self.Y_train = training_data[\"Target\"].to_frame()\n",
    "            \n",
    "            self.X_dev = dev_data.drop([\"Target\", \"RowId\"], axis = 1)\n",
    "            self.Y_dev = dev_data[\"Target\"].to_frame()\n",
    "            \n",
    "            self.X_test = test_data.drop([\"Target\", \"RowId\"], axis = 1)\n",
    "            self.Y_dev = test_data[\"Target\"].to_frame()\n",
    "            \n",
    "            return \n",
    "\n",
    "        self._trades = pd.read_csv(self.TRAINING_DIRECTORY + \"trades.csv\")\n",
    "        self._stock_list = pd.read_csv(\"stock_list.csv\")\n",
    "        self.seed = seed\n",
    "        \n",
    "        prices_df = pd.read_csv(self.TRAINING_DIRECTORY + \"stock_prices.csv\").fillna(0)\n",
    "        supp_prices_df = pd.read_csv(self.SUPPLEMENTAL_DIRECTORY + \"stock_prices.csv\").fillna(0)\n",
    "        extra_training_df = supp_prices_df[supp_prices_df.Date < \"2021-06-1\"]\n",
    "        \n",
    "        self._stock_prices = pd.concat([prices_df, extra_training_df])\n",
    "        \n",
    "        X = self._stock_prices.drop([\"Target\", \"RowId\"], axis = 1)\n",
    "        y = self._stock_prices[\"Target\"]\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = train_size, random_state = seed)\n",
    "        self.X_train = pd.DataFrame(x_train, columns = X.columns)\n",
    "        self.Y_train = pd.DataFrame(y_train, columns = [\"Target\"])\n",
    "       \n",
    "        stock_prices_d = supp_prices_df[supp_prices_df.Date >= \"2021-06-1\"]\n",
    "        self.X_dev = stock_prices_d.drop([\"Target\", \"RowId\"], axis = 1)\n",
    "        self.Y_dev = stock_prices_d[\"Target\"].to_frame()\n",
    "       \n",
    "        self.X_test = pd.DataFrame(x_test, columns = self._stock_prices.columns)\n",
    "        self.Y_test = pd.DataFrame(y_test, columns = [\"Target\"])\n",
    "        \n",
    "    def stocks(self) -> np.ndarray:\n",
    "        return self._stock_prices[\"SecuritiesCode\"].unique()\n",
    "      \n",
    "    def add_features(self):\n",
    "        def _add_features(df: pd.DataFrame) -> pd.DataFrame:            \n",
    "            # Add 3 day vwap \n",
    "            df[\"Adjusted\"] = (df['Low'] + df['High'] + df['Close']) / 3\n",
    "            df[\"Vwap\"] = df[\"Adjusted\"]\n",
    "            \n",
    "            df.sort_values([\"SecuritiesCode\", \"Date\"], inplace = True)\n",
    "            n_days = len(df[\"Date\"].unique())\n",
    "            \n",
    "            for i in range(len(df)):\n",
    "                if i % n_days < 2:\n",
    "                    continue \n",
    "                curr = df.iloc[i]\n",
    "                prev1 = df.iloc[i - 1]\n",
    "                prev2 = df.iloc[i - 2]\n",
    "                \n",
    "                vol_sum = curr[\"Volume\"] + prev1[\"Volume\"] + prev2[\"Volume\"]\n",
    "                weighted_price = (curr[\"Adjusted\"] * curr[\"Volume\"] + prev1[\"Adjusted\"] * prev1[\"Volume\"] + prev2[\"Adjusted\"] * prev2[\"Volume\"])\n",
    "                \n",
    "                if math.isnan(vol_sum) or math.isnan(weighted_price) or vol_sum == 0:\n",
    "                    continue \n",
    "                    \n",
    "                df[\"Vwap\"].iloc[i] = (weighted_price / vol_sum) if vol_sum != 0 else df[\"Vwap\"].iloc[i]\n",
    "            \n",
    "            df.sort_values([\"Date\", \"SecuritiesCode\"], inplace = True)\n",
    "            df.drop([\"Adjusted\"], axis = 1, inplace = True)\n",
    "            return df\n",
    "            \n",
    "            # * Feel free to add your own features\n",
    "            \n",
    "        self.X_train = _add_features(self.X_train)\n",
    "        self.X_dev = _add_features(self.X_dev)\n",
    "        self.X_test = _add_features(self.X_test)\n",
    "        \n",
    "    def x_train(self, security = None) -> pd.DataFrame:\n",
    "        if security is not None:\n",
    "            return self.X_train[self.X_train[\"SecuritiesCode\"] == security]\n",
    "        \n",
    "        return self.X_train\n",
    "        \n",
    "    def x_test(self, security = None) -> pd.DataFrame:\n",
    "        if security is not None:\n",
    "            return self.X_test[self.X_test[\"SecuritiesCode\"] == security]            \n",
    "\n",
    "        return self.X_test\n",
    "    \n",
    "    def x_dev(self, security = None) -> pd.DataFrame:\n",
    "        if security is not None:\n",
    "            return self.X_dev[self.X_dev[\"SecuritiesCode\"] == security]\n",
    "        \n",
    "        return self.X_dev\n",
    "    \n",
    "    def y_dev(self, security = None) -> pd.DataFrame:\n",
    "        if security is not None:\n",
    "            return self.Y_dev[self.Y_dev[\"SecuritiesCode\"] == security]\n",
    "        \n",
    "        return self.Y_dev\n",
    "\n",
    "    def y_train(self, security = None) -> pd.DataFrame:            \n",
    "        if security is not None:\n",
    "            return self.Y_train[self.Y_train[\"SecuritiesCode\"] == security]   \n",
    "        \n",
    "        return self.Y_train  \n",
    "            \n",
    "    def y_test(self, security = None) -> pd.DataFrame:\n",
    "        if security is not  None:\n",
    "            return self.Y_test[self.X_test[\"SecuritiesCode\"] == security]\n",
    "        \n",
    "        return self.Y_test\n",
    "        \n",
    "    def stock_list(self) -> pd.DataFrame:\n",
    "        return self._stock_list\n",
    "    \n",
    "    def trades(self) -> pd.DataFrame:\n",
    "        return self._trades\n",
    "    \n",
    "    def stock_prices(self) -> pd.DataFrame:\n",
    "        return self._stock_prices\n",
    "    \n",
    "    def get_seed(self) -> int:\n",
    "        return self.seed \n",
    "    \n",
    "    def export_to_csv(self, X: pd.DataFrame, y: pd.DataFrame, filename: str):\n",
    "        '''\n",
    "            Args:\n",
    "                - X: DataFrame corresponding the features you want to export\n",
    "                - y: DataFrame corresponding to the target you want to export\n",
    "            Effect:\n",
    "                - Add y as a column to X and export the DataFrame to a .csv file with the given filename\n",
    "        '''\n",
    "        df = pd.concat([X, y], axis = 1)\n",
    "        df.to_csv(filename)\n",
    "    \n",
    "ds = DataSet()\n",
    "# ds.add_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(X, y, filename: str):\n",
    "    df = pd.concat([X, y], axis = 1)\n",
    "    df.to_csv(filename)\n",
    "    \n",
    "export_to_csv(ds.x_train(), ds.y_train(), \"train.csv\")\n",
    "export_to_csv(ds.x_dev(), ds.y_dev(), \"dev.csv\")\n",
    "export_to_csv(ds.x_test(), ds.y_test(), \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_price(securities_code):\n",
    "    df = ds.stock_prices()\n",
    "    df[df[\"SecuritiesCode\"] == securities_code].plot(x = \"Date\", y = \"Close\", figsize=(8,4))\n",
    "    plt.ylabel(\"Close\")\n",
    "    plt.title(\"Close for {}\".format(securities_code))\n",
    "    plt.locator_params(axis='x', nbins=8)\n",
    "    plt.show()\n",
    "\n",
    "def plot_stock_target(securities_code):\n",
    "    df = ds.stock_prices()\n",
    "    df[df[\"SecuritiesCode\"] == securities_code].plot(x = \"Date\", y = \"Target\", figsize=(8,4))\n",
    "    plt.ylabel(\"Target\")\n",
    "    plt.title(\"Target for {}\".format(securities_code))\n",
    "    plt.locator_params(axis='x', nbins=8)\n",
    "    plt.show()\n",
    "\n",
    "plot_stock_price(6502)\n",
    "plot_stock_target(6502)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's Linear Models\n",
    "class LinearModels:\n",
    "    '''\n",
    "    - This class is used to train and test various linear models such as LinearRegression, RidgeRegression and ElasticNet\n",
    "    - The features used are those in the basic_features list.\n",
    "    - For each model, the MSE is calculated and the predictions are plotted against the true target values from the test set.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.features = [\n",
    "            \"Open\",\n",
    "            \"High\",\n",
    "            \"Low\",\n",
    "            \"Close\",\n",
    "            \"Volume\",\n",
    "            \"AdjustmentFactor\",\n",
    "            \"ExpectedDividend\",\n",
    "            \"SupervisionFlag\",\n",
    "            # \"Vwap\"\n",
    "        ]\n",
    "        self.ds = DataSet()\n",
    "        \n",
    "        self.lr_model = None\n",
    "        self.rg_model = None\n",
    "        self.en_model = None\n",
    "        self.trained = False\n",
    "    \n",
    "    def get_linear_regression(self):\n",
    "        if not self.trained:\n",
    "            print(\"Please train the models first\")\n",
    "            return\n",
    "        return self.lr_model\n",
    "        \n",
    "    def get_ridge_regression(self):\n",
    "        if not self.trained:\n",
    "            print(\"Please train the models first\")\n",
    "            return \n",
    "        return self.rg_model\n",
    "    \n",
    "    def get_features(self) -> list:\n",
    "        return self.features\n",
    "    \n",
    "    def train(self):\n",
    "        if self.trained:\n",
    "            return \n",
    "    \n",
    "        x_train = self.ds.x_train()[self.features]\n",
    "        y_train = self.ds.y_train() \n",
    "        \n",
    "        x_dev = self.ds.x_dev()[self.features]\n",
    "        y_dev = self.ds.y_dev()\n",
    "        \n",
    "        cv_alpha = make_pipeline(\n",
    "            StandardScaler(), \n",
    "            RidgeCV(alphas = np.logspace(-6, 6, 13))\n",
    "        ).fit(x_dev, y_dev).named_steps['ridgecv'].alpha_\n",
    "        \n",
    "        print(f\"The best alpha for Ridge Regression is {cv_alpha}\")\n",
    "        \n",
    "        self.lr_model = make_pipeline(StandardScaler(), LinearRegression()).fit(x_train, y_train)\n",
    "        self.rg_model = make_pipeline(StandardScaler(), Ridge(alpha = cv_alpha)).fit(x_train, y_train)\n",
    "        self.en_model = make_pipeline(StandardScaler(), ElasticNet()).fit(x_train, y_train)\n",
    "        \n",
    "        self.trained = True \n",
    "        \n",
    "    def compute_losses(self):\n",
    "        if not self.trained:\n",
    "            print(\"Please train the models first\")\n",
    "            return\n",
    "    \n",
    "        def compute_loss(model, model_name):\n",
    "            x_test = self.ds.x_test()[self.features]\n",
    "            y_test = self.ds.y_test()\n",
    "            \n",
    "            y_pred = model.predict(x_test)\n",
    "            mse = float(mean_squared_error(y_test, y_pred))\n",
    "            \n",
    "            plt.scatter(y_test, y_pred)\n",
    "            plt.xlabel(\"True Target\")\n",
    "            plt.ylabel(\"Predicted Target\")\n",
    "            plt.title(f\"Predictions for {model_name} (MSE: {mse})\")\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"MSE for {} is {}\".format(model_name, mse))\n",
    "\n",
    "        compute_loss(self.lr_model, \"Linear Regression\")\n",
    "        compute_loss(self.rg_model, \"Ridge Regression\")\n",
    "        compute_loss(self.en_model, \"Elastic Net\")\n",
    "            \n",
    "lm = LinearModels()\n",
    "lm.train()\n",
    "# lm.compute_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's Tree Models (with Ensembles)\n",
    "class TreeMethods:\n",
    "    def __init__(self, max_depth = 20):\n",
    "        self.ds = DataSet()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.dt = DecisionTreeRegressor()               # decision tree  \n",
    "        self.dt_optimal_depth = 4                       # ! reset to None when using a new dev set\n",
    "        \n",
    "        self.rf = RandomForestRegressor()               # random forest\n",
    "        self.rf_optimal_params = {                      # ! reset to None when using a new dev set\n",
    "            'max_depth': 6, \n",
    "            'max_features': 4, \n",
    "            'n_estimators': 50\n",
    "        }\n",
    "        \n",
    "        self.gb = GradientBoostingRegressor()           # gradient boosting \n",
    "        self.gb_optimal_params = {                      # ! reset to None when using a new dev set\n",
    "            'learning_rate': 0.1, \n",
    "            'max_depth': 3, \n",
    "            'n_estimators': 35\n",
    "        }\n",
    "        \n",
    "        self.features = [\n",
    "            \"Open\",\n",
    "            \"High\",\n",
    "            \"Low\",\n",
    "            \"Close\",\n",
    "            \"Volume\",\n",
    "            \"AdjustmentFactor\",\n",
    "            \"ExpectedDividend\",\n",
    "            \"SupervisionFlag\",\n",
    "            \"Vwap\"\n",
    "        ]\n",
    "        \n",
    "        self.rf_param_grid = {\n",
    "            'max_depth': range(2, self.max_depth, 2),\n",
    "            'max_features': range(2, len(self.features)),\n",
    "            'n_estimators': [ 5, 10, 20, 35, 50 ]\n",
    "        }\n",
    "        self.gb_param_grid = {\n",
    "            'max_depth': range(2, int(self.max_depth / 2)),\n",
    "            'learning_rate': [ 0.01, 0.05, 0.1, 0.2 ],\n",
    "            'n_estimators': [ 5, 10, 20, 35, 50 ]\n",
    "        }\n",
    "        self.trained = False \n",
    "        \n",
    "    def get_models(self) -> tuple:\n",
    "        return (self.dt, self.rf, self.gb)\n",
    "    \n",
    "    def get_features(self) -> list:\n",
    "        return self.features\n",
    "    \n",
    "    def _dt_cross_validation(self):\n",
    "        x_train = self.ds.x_train()[self.features]\n",
    "        y_train = self.ds.y_train()\n",
    "        x_dev = self.ds.x_dev()[self.features]\n",
    "        y_dev = self.ds.y_dev()\n",
    "        score = 0\n",
    "        best_depth = 2\n",
    "        for depth in range(2, self.max_depth):\n",
    "            dtr = DecisionTreeRegressor(max_depth = depth)\n",
    "            dtr.fit(x_train, y_train)\n",
    "            \n",
    "            # using r-squared as the metric for determining the best depth because it measures best fit\n",
    "            dev_score = dtr.score(x_dev, y_dev)\n",
    "            if dev_score > score:\n",
    "                score = dev_score\n",
    "                best_depth = depth\n",
    "        print(f\"Best depth is for Decision Tree is {self.dt_optimal_depth}\")   \n",
    "        return best_depth\n",
    "            \n",
    "    def _rf_cross_validation(self):\n",
    "        x_dev = self.ds.x_dev()[self.features]\n",
    "        y_dev = self.ds.y_dev()\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator = RandomForestRegressor(random_state = ds.get_seed()),\n",
    "            param_grid = self.rf_param_grid,\n",
    "            cv = KFold(n_splits = 5, shuffle = True, random_state = ds.get_seed() + 1))\n",
    "        grid_search.fit(x_dev, y_dev.values.ravel())\n",
    "        print(f\"Best parameters for Random Forest are {self.rf_optimal_params}\")\n",
    "        return grid_search.best_params_\n",
    "    \n",
    "    def _gb_cross_validation(self):\n",
    "        x_dev = self.ds.x_dev()[self.features]\n",
    "        y_dev = self.ds.y_dev()\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator = GradientBoostingRegressor(random_state = ds.get_seed()),\n",
    "            param_grid = self.gb_param_grid,\n",
    "            cv = KFold(n_splits = 5, shuffle = True, random_state = ds.get_seed() + 1))\n",
    "        grid_search.fit(x_dev, y_dev.values.ravel())\n",
    "        print(f\"Best parameters for Gradient Boosting are {self.gb_optimal_params}\")\n",
    "        return grid_search.best_params_\n",
    "    \n",
    "    def train(self):\n",
    "        if self.trained:\n",
    "            return \n",
    "        x_train = self.ds.x_train()[self.features]\n",
    "        y_train = self.ds.y_train()\n",
    "        seed = ds.get_seed()\n",
    "        \n",
    "        if self.dt_optimal_depth is None:\n",
    "            self.dt_optimal_depth = self._dt_cross_validation() \n",
    "            \n",
    "        self.dt = DecisionTreeRegressor(max_depth = self.dt_optimal_depth).fit(x_train, y_train)\n",
    "        \n",
    "        if self.rf_optimal_params is None:\n",
    "            self.rf_params = self._rf_cross_validation()\n",
    "        \n",
    "        self.rf = RandomForestRegressor(\n",
    "            n_estimators = self.rf_optimal_params[\"n_estimators\"], \n",
    "            max_features = self.rf_optimal_params[\"max_features\"],\n",
    "            max_depth = self.rf_optimal_params[\"max_depth\"],\n",
    "            random_state = seed)\n",
    "        self.rf.fit(x_train, y_train.values.ravel())\n",
    "        \n",
    "        if self.gb_optimal_params is None:    \n",
    "            self.gb_optimal_params = self._gb_cross_validation()        \n",
    "            \n",
    "        self.gb = GradientBoostingRegressor(\n",
    "            n_estimators = self.gb_optimal_params[\"n_estimators\"],\n",
    "            max_depth = self.gb_optimal_params[\"max_depth\"],\n",
    "            learning_rate = self.gb_optimal_params[\"learning_rate\"], \n",
    "            random_state = seed)\n",
    "        self.gb.fit(x_train, y_train.values.ravel())\n",
    "        \n",
    "        self.trained = True \n",
    "        \n",
    "    def compute_losses(self):\n",
    "        if not self.trained:\n",
    "            print(\"Please train the models first\")\n",
    "            return\n",
    "        \n",
    "        x_test = self.ds.x_test()[self.features]\n",
    "        y_test = self.ds.y_test()\n",
    "        \n",
    "        def compute_loss(model, model_name):\n",
    "            y_pred = model.predict(x_test)\n",
    "            mse = float(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "            plt.scatter(y_test, y_pred)\n",
    "            plt.xlabel(\"True Target\")\n",
    "            plt.ylabel(\"Predicted Target\")\n",
    "            plt.title(f\"Predictions for {model_name} (MSE: {mse})\")\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            plt.savefig(f\"plots/{model_name}.png\")\n",
    "        \n",
    "        compute_loss(self.dt, \"DecisionTreeRegressor\")\n",
    "        compute_loss(self.rf, \"RandomForestRegressor\")\n",
    "        compute_loss(self.gb, \"GradientBoostingRegressor\")\n",
    "        \n",
    "tm = TreeMethods()\n",
    "tm.train()\n",
    "# tm.compute_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's Ensemble Litrature Findings\n",
    "'''\n",
    "    [Mehta S, Rana P, Singh S, Sharma A, Agarwal P. Ensemble learning approach for enhanced stock prediction.]\n",
    "        Their results show that the ensemble learning technique attained maximum accuracy with lesser variance in stock prediction.\n",
    "        \n",
    "    [Kohli PPS, Zargar S, Arora S, Gupta P. Stock prediction using machine learning algorithms.]\n",
    "        Kohli et al. [46] examined different ML algorithms (SVM, RF, Gradient Boosting and AdaBoost) performance in stock market price prediction. \n",
    "        The study showed that AdaBoost outperformed Gradient Boosting in terms of predicting accuracy.\n",
    "    \n",
    "    [Ren Y, Suganthan PN, Srikanth N. Ensemble methods for wind and solar power forecastingâ€”a state-of-the-art review.]\n",
    "        Thus, EMs highlights the strong point and watered-down the feebleness of the single classifiers. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition\n",
    "\n",
    "# Code supplied by competition host\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n",
    "        assert df['Rank'].min() == 0\n",
    "        assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)        # type: ignore\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio\n",
    "\n",
    "def check_score(X, model, features):\n",
    "    '''\n",
    "    Args:\n",
    "        X: DataFrame containing the features of the test set you wish to use\n",
    "        model: model you wish to use to make the prediction\n",
    "        features: features you used to train the model\n",
    "    Effect:\n",
    "        prints the sharpe ratio (score) of the metric on the test set\n",
    "    '''\n",
    "    \n",
    "    def add_rank(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df[\"Rank\"] = df.groupby(\"Date\")[\"Target\"].rank(ascending = False, method = \"first\") - 1\n",
    "        df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n",
    "        return df\n",
    "    \n",
    "    predicted_targets = model.predict(X[features])\n",
    "    submission = pd.DataFrame(X[[\"Date\", \"SecuritiesCode\"]])\n",
    "    submission[\"Target\"] = predicted_targets\n",
    "    submission = add_rank(submission)\n",
    "    score = round(calc_spread_return_sharpe(submission), 5)\n",
    "    \n",
    "    print(f\"Score: {score}\")\n",
    "\n",
    "lr = lm.get_linear_regression()\n",
    "check_score(ds.x_test(), lr, lm.get_features())\n",
    "\n",
    "gb = tm.get_models()[2]\n",
    "check_score(ds.x_test(), gb, tm.get_features())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
